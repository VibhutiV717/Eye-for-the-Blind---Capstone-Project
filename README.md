# Eye for the Blind â€“ Deep Learning Capstone Project

This project is a deep learning-based assistive solution designed to help visually impaired individuals by recognizing and interpreting their environment. It uses computer vision to identify objects and provide audio feedback.

## ðŸ›  Tools & Technologies
- Python
- TensorFlow / Keras
- OpenCV
- CNN (Convolutional Neural Networks)
- Text-to-Speech (TTS) libraries
- Google Colab

## Dataset
The project is an extended application of Show, Attend and Tell: Neural Image Caption Generation with Visual Attention paper.
The dataset is taken from the Kaggle website and it consists of sentence-based image descriptions having a list of 8,000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events of the image.

## ðŸ“Œ Objective
To build a prototype that can capture visual input, detect objects, and provide spoken output to assist blind or visually impaired users in understanding their surroundings.

## ðŸ“ Project Structure
- `eye_for_the_blind.ipynb` â€“ Main notebook with model and implementation
- `README.md` â€“ Project overview
- Any TTS setup or demo code snippets included

---

> Note: Due to limitations, live camera input and full TTS setup may be simulated or represented with sample code.
